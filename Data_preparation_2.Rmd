---
title: "Data preparation"
#bibliography: references.bib
author: "Niels Vullings"
bibliography: references.bib
---

```{=html}
<style>
body {
text-align: justify}
</style>
```

```{r, globalsettings, echo=FALSE, warning=FALSE, results='hide'}
library(knitr)

knitr::opts_chunk$set(echo = TRUE)
opts_chunk$set(tidy.opts=list(width.cutoff=100),tidy=TRUE, warning = FALSE, message = FALSE,comment = "#>", cache=TRUE, class.source=c("test"), class.output=c("test2"))
options(width = 100)
rgl::setupKnitr()

```

```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy(position = c('top', 'right'))
# klippy::klippy(color = 'darkgreen')
#klippy::klippy(tooltip_message = 'Click to copy', tooltip_success = 'Done')
```

Last compiled on `r format(Sys.time(), '%B, %Y')`

<br>

------------------------------------------------------------------------

# Functions
```{r}
rm(list = ls())
```

## UDF
```{r}
colorize <- function(x, color) {sprintf("<span style='color: %s;'>%s</span>", color, x) }

fpackage.check <- function(packages) {
  lapply(packages, FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
      install.packages(x, dependencies = TRUE)
      library(x, character.only = TRUE)
    }
  })
}

fsave <- function(x, file = NULL, location = "./data/processed/") {
  ifelse(!dir.exists("data"), dir.create("data"), FALSE)
  ifelse(!dir.exists("data/processed"), dir.create("data/processed"), FALSE)
  if (is.null(file))
    file = deparse(substitute(x))
  datename <- substr(gsub("[:-]", "", Sys.time()), 1, 8)
  totalname <- paste(location, datename, file, ".rda", sep = "")
  save(x, file = totalname)  #need to fix if file is reloaded as input name, not as x. 
}

fload <- function(filename) {
  load(filename)
  get(ls()[ls() != "filename"])
}

fshowdf <- function(x, ...) {
  knitr::kable(x, digits = 2, "html", ...) %>%
    kableExtra::kable_styling(bootstrap_options = c("striped", "hover")) %>%
    kableExtra::scroll_box(width = "100%", height = "300px")
}

#---- String Stripper ----
str_strip <- function(input = "THIs StrïnG is ÑorMälìZed"){
  
  
  string <- tolower(input)
  string <- iconv(string, from = 'UTF-8', to = 'ASCII//TRANSLIT')
  string <- sub(".* ", "", string)
  
  # string <- gsub("[[:punct:]]", " ", string)
  
  return(string)
}

# str_strip(df_ego$Naam)
```

## User function for Network data creation

About the parameters:

data: our scholars file university: Character vector with names of universities. We have several universities in the Netherlands. See above for relevant names.

discipline: Character vector, either sociology or political science or both. waves: a list of numeric vectors with start and end year of wave.

type: "first": directed: first author sending to others "last": directed: last author sending to others "all": undirected: ties between all authors

Output: a list

-   \$nets: array of nomination networks.

-   \$data: sample of data (scholars)

```{r}
fcolnet <- function(data = scholars, university = "RU", discipline = "sociology", waves = list(c(2015,
                                                                                                 2018), c(2019, 2023)), type = c("first")) {
  
  # step 1
  demographics <- do.call(rbind.data.frame, data$demographics)
  demographics <- demographics %>%
    mutate(Universiteit1.22 = replace(Universiteit1.22, is.na(Universiteit1.22), ""), Universiteit2.22 = replace(Universiteit2.22,
                                                                                                                 is.na(Universiteit2.22), ""), Universiteit1.24 = replace(Universiteit1.24, is.na(Universiteit1.24),
                                                                                                                                                                          ""), Universiteit2.24 = replace(Universiteit2.24, is.na(Universiteit2.24), ""), discipline.22 = replace(discipline.22,
                                                                                                                                                                                                                                                                                  is.na(discipline.22), ""), discipline.24 = replace(discipline.24, is.na(discipline.24), ""))
  
  sample <- which((demographics$Universiteit1.22 %in% university | demographics$Universiteit2.22 %in%
                     university | demographics$Universiteit1.24 %in% university | demographics$Universiteit2.24 %in%
                     university) & (demographics$discipline.22 %in% discipline | demographics$discipline.24 %in% discipline))
  
  demographics_soc <- demographics[sample, ]
  scholars_sel <- lapply(scholars, "[", sample)
  
  # step 2
  ids <- demographics_soc$au_id
  nwaves <- length(waves)
  nets <- array(0, dim = c(nwaves, length(ids), length(ids)), dimnames = list(wave = 1:nwaves, ids,
                                                                              ids))
  dimnames(nets)
  
  # step 3
  df_works <- tibble(works_id = unlist(lapply(scholars_sel$work, function(l) l$id)), works_author = unlist(lapply(scholars_sel$work,
                                                                                                                  function(l) l$author), recursive = FALSE), works_year = unlist(lapply(scholars_sel$work, function(l) l$publication_year),
                                                                                                                                                                                 recursive = FALSE))
  
  df_works <- df_works[!duplicated(df_works), ]
  
  # step 4
  if (type == "first") {
    for (j in 1:nwaves) {
      df_works_w <- df_works[df_works$works_year >= waves[[j]][1] & df_works$works_year <= waves[[j]][2],
      ]
      for (i in 1:nrow(df_works_w)) {
        ego <- df_works_w$works_author[i][[1]]$au_id[1]
        alters <- df_works_w$works_author[i][[1]]$au_id[-1]
        if (sum(ids %in% ego) > 0 & sum(ids %in% alters) > 0) {
          nets[j, which(ids %in% ego), which(ids %in% alters)] <- 1
        }
      }
    }
  }
  
  if (type == "last") {
    for (j in 1:nwaves) {
      df_works_w <- df_works[df_works$works_year >= waves[[j]][1] & df_works$works_year <= waves[[j]][2],
      ]
      for (i in 1:nrow(df_works_w)) {
        ego <- rev(df_works_w$works_author[i][[1]]$au_id)[1]
        alters <- rev(df_works_w$works_author[i][[1]]$au_id)[-1]
        if (sum(ids %in% ego) > 0 & sum(ids %in% alters) > 0) {
          nets[j, which(ids %in% ego), which(ids %in% alters)] <- 1
        }
      }
    }
  }
  
  if (type == "all") {
    for (j in 1:nwaves) {
      df_works_w <- df_works[df_works$works_year >= waves[[j]][1] & df_works$works_year <= waves[[j]][2],
      ]
      for (i in 1:nrow(df_works_w)) {
        egos <- df_works_w$works_author[i][[1]]$au_id
        if (sum(ids %in% egos) > 0) {
          nets[j, which(ids %in% egos), which(ids %in% egos)] <- 1
        }
      }
    }
  }
  output <- list()
  output$data <- scholars_sel
  output$nets <- nets
  return(output)
}

```

# Set up
```{r}

packages <- c("data.table", "tidyverse", "xml2", "rvest")
fpackage.check(packages)
```

# Load data
```{r}
scholars <- fload("data/scholars_20240924.rda")

```

# Data Manipulation

## Subset relevant data

I want to study the Sociology departments

```{r}

soc_data <- fcolnet(data = scholars, 
                    university = c("RU", "UU"), 
                    discipline = c("sociology"), 
                    waves = list(c(2015, 2019), c(2020, 2024)), 
                    type = c("first"))


df_ego <- do.call(rbind.data.frame, soc_data$data$demographics)


# soc_data$nets[2,,] # How to call a specific network

```

## Gender

In order to get use scrape first names, we first need to have the first names of all authors in our network

### Screwing around with strings
```{r}
vect <- c("Now this string is not split", "It is a nice Picture", "Is it ready", "Split Screen")

vect
# ?nchar()

testje <- data.frame(string = vect, job = c(TRUE,TRUE,TRUE,FALSE))

testje

testje$first_el <- sapply(strsplit(vect, " "), `[`, 1) # This code should work as a way to extract first names from the ego characteristics dataset
testje

```

### Extract first names
```{r}

x <- data.frame(Naam = df_ego$Naam)

first_name <- sapply(strsplit(x$Naam, " "), `[`, 1) # This code should work as a way to extract first names from the ego characteristics dataset



df_names <- data.frame(x,first_name, male = NA, female = NA) # seem to have worked

head(df_names)
```

### Gender Scraper

The function gender_scraper uses HTML-scraping with rvest to extract first names from a string with one's full name. Input can be any dataframe that contains names, but this one is specifically made to be compatible with the '*fcolnet*' function by Jochem Tolsma. The function first extracts the first element of a string and saves it in variable first_name. I then loop over every first name in the dataframe, with each first name serving as new input for the "voornamenbank" <https://nvb.meertens.knaw.nl/>. If the name is in the database, the function will extract the occurences of the name by gender. If the name is not in the database, the function will return a NA value for the gender of that respondent. The final step is creating a scaled (0/1) variable '[*perc_female*]{.underline}', which represents the likelihood that a name corresponds with the female gender (1 = 100% female, 0 = 100% male).

```{r}
# df_names <- df_names[1:5,] # take first elements to try out

i <- 1
df_names$first_name[i]


gender_scraper.NV <- function(names = "names element", web_page = "https://nvb.meertens.knaw.nl/naam/is/"){
  
  
  names$first_name <- sapply(strsplit(names$Naam, " "), `[`, 1) # This code should work as a way to extract first names from the ego characteristics dataset
  names$male <- NA
  names$female <- NA
  
  for(i in 1:nrow(names)){
    
    # print(names$first_name[i])
    
    web_page <- read_html(paste0("https://nvb.meertens.knaw.nl/naam/is/", names$first_name[i]))
    
    table <- web_page %>% 
      rvest::html_elements("body") %>% 
      rvest::html_elements("table") %>% 
      rvest::html_table()
    
    if(length(table) == 0){
      
      print(length(table))
      
      names$male[i] <- NA
      names$female[i] <- NA
      
    } else{
      
      # print(table)
      # print(table[[1]][[2,3]]) # Check if values for male are coherent and accurate
      # print(table[[1]][[6,3]]) # Check if values for female are coherent and accurate
      
      names$male[i] <- as.numeric(ifelse(table[[1]][[2,3]] == "--", 0, table[[1]][[2,3]])) # Make sure non-occurences are not registered as "--"
      names$female[i] <- as.numeric(ifelse(table[[1]][[6,3]] == "--", 0, table[[1]][[6,3]])) # Make sure non-occurences are not registered as "--"
      
      
    }
    
  } # end forloop
  
  names <- names %>% mutate(perc_female = case_when(is.na(female == TRUE) & is.na(male) == TRUE ~ NA,
                                                    is.na(female) == TRUE ~ 0,
                                                    is.na(male == TRUE) ~ 1,
                                                    .default = round((female/(male + female)),2))) %>% 
    select(!c(male,female, first_name))
  
  return(names)
  
  
} # end function

# ?mutate()
# ?case_when
df_ego <- gender_scraper.NV(names = df_ego, web_page = "https://nvb.meertens.knaw.nl/naam/is/")


# paste0("https://nvb.meertens.knaw.nl/naam/is/", "name") # This will eventually be used for automating the scraping process

```

### Check results

```{r}
check <- df_ego %>% count(perc_female)

plot(check$perc_female, check$n)
```

## Journal Rankings
### Extract works and check journals

```{r}

df_works <- do.call(rbind.data.frame, soc_data$data$works) # put works in dataframe
# head(df_works)

# test1 <- df_works %>% select(id, so, issn_l, author) # test the works

```

### Load journal ranking data

```{r}
dat <- read_csv2("data/scimagojr_23_journals_all.csv")
# head(dat)

```

### Split the ISSN codes if 2 are available

```{r}
dat$Issn_1 <- sapply(strsplit(dat$Issn, ", "), `[`, 1) # This code should work as a way to split the two issn codes
dat$Issn_2 <- sapply(strsplit(dat$Issn, ", "), `[`, 2)

# dat$Issn_1[1]
# str_length(dat$Issn_1[1])

dat$Issn_1 <- paste0(substr(dat$Issn_1, 1,4), "-", substr(dat$Issn_1, 5,8)) # Hyphenate the codes to match the target df 
dat$Issn_2 <- ifelse(is.na(dat$Issn_2) == TRUE, NA, paste0(substr(dat$Issn_2, 1,4), "-", substr(dat$Issn_2, 5,8))) # Hyphenate the codes, but make non-existing second codes NA

df_pres <- dat %>% select(Rank, Title, Issn_1, Issn_2, SJR, `SJR Best Quartile`, `H index`, `%Female`) # Make a set that will be joined with df_works

```

### check compatability

```{r}

# df_works %>% select(issn_l)
# df_pres %>% select(Issn_1, Issn_2)
df_works$check <- ifelse(df_works$issn_l %in% df_pres$Issn_1 | df_works$issn_l %in% df_pres$Issn_2, 1,0)

mis_journal <- df_works %>% filter(check == 0)

# as.data.frame(unique(mis_journal$so)) # Still left with 166 missing journals

```

### Create ID variable

```{r}
df_pres <- df_pres %>% mutate(issn_l = case_when(Issn_1 %in% df_works$issn_l == TRUE ~ Issn_1,
                                                 Issn_2 %in% df_works$issn_l == TRUE ~ Issn_2,
                                                 .default = NA)) %>% filter(!is.na(issn_l))
```

### Looping algorithm logic
The idea is to loop over every item in the list 'works', so that we can merge a journal ranking based on if someone in our target dataset has published the article

```{r}
list_works <- soc_data$data$works

df_ego$Q1.W1 <- 0
df_ego$Q1.W2 <- 0

for (i in 1:length(list_works)){
  
  wave1s <- 2015
  wave1e <- 2019
  wave2s <- 2020
  wave2e <- 2024
  
  works <- list_works[[i]]
  
  works <- works %>% left_join(df_pres, by = "issn_l", multiple = "all")
  works$`SJR Best Quartile` <- ifelse(is.na(works$`SJR Best Quartile`), "No Rank", works$`SJR Best Quartile`)
  
  au <- works %>% unnest(author) %>% 
    mutate(check_id = au_id %in% df_ego$au_id) %>% 
    mutate(check_nam = str_strip(au_display_name) %in% str_strip(df_ego$Naam)) %>% 
    filter(check_id == TRUE & check_nam == TRUE)
  
  works <- works %>% mutate(waves = case_when(publication_year >= wave1s & publication_year <= wave1e ~ "Wave 1",
                                              publication_year >= wave2s & publication_year <= wave2e ~ "Wave 2",
                                              .default = "NA")) %>% filter(waves != "NA")
  if(nrow(works) == 0){
    
    next
    
  } else {
    
    for(x in 1:nrow(works)){
      
      if(works$waves[x] == "Wave 1"){
        
        if(works$`SJR Best Quartile`[x] == "Q1"){
          
          naam <- works$author[[x]]$au_display_name
          df_ego[str_strip(df_ego$Naam) %in% str_strip(naam),]$Q1.W1 <- df_ego[str_strip(df_ego$Naam) %in% str_strip(naam),]$Q1.W1 + 1
          
        }
      } else{
        
        if(works$`SJR Best Quartile`[x] == "Q1"){
          
          naam <- works$author[[x]]$au_display_name
          df_ego[str_strip(df_ego$Naam) %in% str_strip(naam),]$Q1.W2 <- df_ego[str_strip(df_ego$Naam) %in% str_strip(naam),]$Q1.W2 + 1
          
        }
      }    
      
    }
    
    
    
  }
  
}

```


## Author H-index`
```{r}
# Add h-index and i10-index columns to df_ego
df_ego <- df_ego %>%
  mutate(h_index = NA_real_, i10_index = NA_real_)

# Get H-index and i10-index 
get_openalex_metrics <- function(openalex_id) {
  url <- paste0("https://api.openalex.org/authors/", openalex_id)
  author_data <- tryCatch({
    jsonlite::fromJSON(url)
  }, error = function(e) {
    message(paste("Error fetching data for OpenAlex ID:", openalex_id))
    return(NULL)
  })
  
  if (!is.null(author_data)) {
    h_index <- author_data$summary_stats$h_index
    i10_index <- author_data$summary_stats$i10_index
    works_count <- author_data$works_count
    cited_by_count <- author_data$cited_by_count
    return(list(h_index = h_index, i10_index = i10_index, works_count = works_count, cited_by_count = cited_by_count))
  } else {
    return(list(h_index = NA, i10_index = NA, works_count = NA, cited_by_count = NA))
  }
}

# Loop for each scholar 
for (i in 1:nrow(df_ego)) {
  openalex_id <- df_ego$au_id[i]  # assuming au_id is the OpenAlex ID in df_ego
  metrics <- get_openalex_metrics(openalex_id)
  df_ego$h_index[i] <- metrics$h_index
  df_ego$i10_index[i] <- metrics$i10_index
  df_ego$works_count[i] <- metrics$works_count
  df_ego$cited_by_count[i] <- metrics$cited_by_count
}

# View updated df_ego with h-index and i10-index
View(df_ego)
```

## Ethnicity
This data was very graciously "borrowed" from Hannah Groennou, who scraped data on country of origin and skin color for multiple universities. 
```{r}
ethnicity <- readr::read_csv("data/demographics_HG.csv") %>%
  select(au_id, white_or_not) %>%
  rename(ethnicity = white_or_not)

df_ego <- df_ego %>% left_join(ethnicity, by = "au_id")

```

## Career age
```{r, warning=FALSE}
df_career_age <- df_works %>%
  unnest(author) %>% # unnesting the tibble from the tibble
  filter(au_id %in% df_ego$au_id == TRUE) %>% # authors in df_works should match authors in df_ego
  group_by(au_id) %>%
  mutate(min_year_pub = min(publication_year, na.rm = TRUE), # initial calculation of minimum year
         count_pub = n()) %>%  # count number of publications
  mutate(first_year_pub = ifelse(count_pub == 1, min_year_pub, # if number of publications is 1, score is min_year_pub
                                 {
                                   filter_year = publication_year[publication_year != min_year_pub] # filter minimum year
                                   mean_pubyear = mean(filter_year, na.rm = TRUE) # calculate mean without min score
                                   valid_year = min(filter_year[filter_year >= (mean_pubyear - 25)], na.rm = TRUE) # minimum year -> range mean-25
                                   valid_year # if number of publications is not 1, than score minimum year with first year removed within range mean-25
                                 })) %>% 
  
  # this line corrects for the warning of returning infinites that for some reason were not filtered through the first ifelse command
  mutate(first_year_pub = ifelse(is.infinite(first_year_pub), min_year_pub, first_year_pub)) %>% #adjusting infinite scores to minimum year
  
  select(au_id, first_year_pub) %>% # selecting variables
  distinct(au_id, first_year_pub, .keep_all = TRUE) # making sure only distinct authors are in data frame  
  

df_ego <- df_ego %>% left_join(df_career_age, by = "au_id")

```


# Save datasets

```{r}
# Save the raw sociology data for RU and UU
save(soc_data, file = "data/processed/soc_data_raw.RData")

# Save the ego data for RU and UU sociologists
save(df_ego, file = "data/processed/RU_UU_ego.RData")

# Save the works for RU and UU sociologists
# save(df_works, file = "data/processed/RU_UU_works.RData")


```

<br>

------------------------------------------------------------------------
